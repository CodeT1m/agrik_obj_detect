{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeT1m/agrik_obj_detect/blob/master/AgrikAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ty1z4wmgZri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30134e20-c92c-442b-e9be-3226002322d1"
      },
      "source": [
        "print(\"Hello colab\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYK19lXWhs69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a31937d-f014-45e0-8aba-483a121860c8"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9lLI2EMhuVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "577f6d9d-1517-4b41-9eeb-4d7db77373d4"
      },
      "source": [
        "!git --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "git version 2.17.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foJQZ0P0hwhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26b72d7c-17b4-4b29-fb29-d92105a986cc"
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/CodeT1m/agrik_obj_detect'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 700000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']\n",
        "\n",
        "print(repo_url)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://github.com/CodeT1m/agrik_obj_detect\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2AXOrtAxgCK",
        "colab_type": "text"
      },
      "source": [
        "# Clone the object_detection_demo repository or fork "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJfR_TbXxpjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3cbe9542-4797-4bf4-ab3a-2668945cbc48"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "print(\"ok\")\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "print(repo_dir_path)\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "ok\n",
            "/content/agrik_obj_detect\n",
            "fatal: destination path 'agrik_obj_detect' already exists and is not an empty directory.\n",
            "/content/agrik_obj_detect\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRAtPQokaTkD",
        "colab_type": "text"
      },
      "source": [
        "#Install Required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3Kxnsnlt4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93a30527-38e5-49dd-930c-baa3c35079dc"
      },
      "source": [
        "#!pip install tensorflow-gpu==1.15\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKvv2DxbaWCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "43e116f4-f6e1-4b3b-c38f-7f3d3de4e0db"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install tf-slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf-slim) (1.12.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLjwfswYarPT",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFaQM8Wmar0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "159961b7-14fb-4255-8028-7293ef5ea256"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/agrik_obj_detect\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0627 06:53:27.959789 140111546222464 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0627 06:53:33.459725 140111546222464 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"generate_tfrecord.py\", line 134, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"generate_tfrecord.py\", line 125, in main\n",
            "    tf_example = create_tf_example(group, path, label_map)\n",
            "  File \"generate_tfrecord.py\", line 54, in create_tf_example\n",
            "    encoded_jpg = fid.read()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
            "    compat.as_bytes(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/agrik_obj_detect/data/images/train/4d439804-01e9-4f5a-bfec-1ef99c882369___RS_NLB.JPG; No such file or directory\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0627 06:53:56.130831 139983165638528 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0627 06:53:57.519227 139983165638528 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/agrik_obj_detect/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GImlo4egj6in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/agrik_obj_detect/data/annotations/test.record'\n",
        "train_record_fname = '/content/agrik_obj_detect/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/agrik_obj_detect/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QnQnTPZj9rW",
        "colab_type": "text"
      },
      "source": [
        "##Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B1TaklrkBFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "471f9caa-73a8-40ea-e54a-eb909e68ff60"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAPz-2GykDhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d304eab7-a1b1-488e-bb7c-7364ce32d1ca"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 63 root   root  4.0K Jun 27 06:54 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlfBqTvHkFoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "982fb90b-4084-4ea9-8eb5-1c3abe2bb6ce"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4lo0nkekHU9",
        "colab_type": "text"
      },
      "source": [
        "#Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBztJfRckNd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DT1WvEMkPQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=35, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dQ4r5fekRw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfrxr7_NkS-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d91d1318-1f48-4be1-eabc-18787d6fd856"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 35\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 700000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/agrik_obj_detect/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/agrik_obj_detect/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/agrik_obj_detect/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/agrik_obj_detect/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIrtDNRKkWa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "#model_dir"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_3b-c2vkXm1",
        "colab_type": "text"
      },
      "source": [
        "#Run Tensorboard Optional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N22ZErgGkaiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "75d0a5af-795d-4b9e-cabd-b0d86abe6117"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-27 14:36:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.233.91.203, 34.238.5.126, 52.5.95.18, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.233.91.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  87%[================>   ]  11.52M  57.6MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  60.4MB/s    in 0.2s    \n",
            "\n",
            "2020-06-27 14:36:33 (60.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQcn3ZENkcmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Sst5n0ke8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1Nw6gfIkgJt",
        "colab_type": "text"
      },
      "source": [
        "###Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK7Igt1okjdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3ad4267-0009-4704-c5ea-25fb7c75aa05"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://94fb0c51fedc.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw5sOwIUkmC8",
        "colab_type": "text"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcALEYGyMdil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=fine_tune_checkpoint,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1, period=5)\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "#selected_model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Loads the weights\n",
        "selected_model.load_weights(fine_tune_checkpoint)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uayJquPacEsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "268fb9b6-3c33-430c-8583-97db3d8e55a3"
      },
      "source": [
        "#Training\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps} \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0627 16:04:29.142115 140526966839168 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 700000\n",
            "I0627 16:04:29.142356 140526966839168 config_util.py:552] Maybe overwriting train_steps: 700000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0627 16:04:29.142461 140526966839168 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0627 16:04:29.142543 140526966839168 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0627 16:04:29.142668 140526966839168 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0627 16:04:29.142765 140526966839168 config_util.py:552] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0627 16:04:29.142883 140526966839168 config_util.py:562] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0627 16:04:29.143634 140526966839168 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0627 16:04:29.143748 140526966839168 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce9d72f198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0627 16:04:29.144165 140526966839168 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce9d72f198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fce839b2510>) includes params argument, but params are not passed to Estimator.\n",
            "W0627 16:04:29.144383 140526966839168 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fce839b2510>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0627 16:04:29.145146 140526966839168 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0627 16:04:29.145320 140526966839168 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0627 16:04:29.145537 140526966839168 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0627 16:04:29.154283 140526966839168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0627 16:04:29.193584 140526966839168 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0627 16:04:29.198886 140526966839168 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0627 16:04:29.218552 140526966839168 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:76: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0627 16:04:39.717049 140526966839168 deprecation.py:323] From /content/models/research/object_detection/inputs.py:76: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0627 16:04:39.811683 140526966839168 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0627 16:04:45.257930 140526966839168 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:258: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 16:04:48.769856 140526966839168 deprecation.py:323] From /content/models/research/object_detection/inputs.py:258: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0627 16:04:51.891584 140526966839168 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0627 16:04:52.074370 140526966839168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:04:54.457544 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:04:54.486609 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:04:54.513884 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:04:54.542360 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:04:54.570898 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:04:54.598866 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "W0627 16:04:54.634675 140526966839168 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0627 16:04:54.634838 140526966839168 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0627 16:04:54.634946 140526966839168 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0627 16:04:54.635043 140526966839168 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0627 16:04:59.232554 140526966839168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0627 16:05:04.989487 140526966839168 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0627 16:05:04.990784 140526966839168 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0627 16:05:08.229360 140526966839168 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-27 16:05:08.229759: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-06-27 16:05:08.234422: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-06-27 16:05:08.234626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2696f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-27 16:05:08.234657: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-27 16:05:08.236737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-27 16:05:08.332390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:05:08.333100: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2697b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-27 16:05:08.333131: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-06-27 16:05:08.333363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:05:08.333908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-27 16:05:08.334265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-27 16:05:08.336174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-27 16:05:08.339420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-27 16:05:08.340068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-27 16:05:08.341901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-27 16:05:08.343286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-27 16:05:08.346172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-27 16:05:08.346328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:05:08.346936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:05:08.347424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-27 16:05:08.347488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-27 16:05:08.348699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-27 16:05:08.348729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-27 16:05:08.348739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-27 16:05:08.348899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:05:08.349637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:05:08.350184: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-27 16:05:08.350228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-77711\n",
            "I0627 16:05:08.352606 140526966839168 saver.py:1284] Restoring parameters from training/model.ckpt-77711\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0627 16:05:10.605257 140526966839168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0627 16:05:11.678316 140526966839168 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0627 16:05:11.987308 140526966839168 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 77711 into training/model.ckpt.\n",
            "I0627 16:05:20.384412 140526966839168 basic_session_run_hooks.py:606] Saving checkpoints for 77711 into training/model.ckpt.\n",
            "2020-06-27 16:05:28.546957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-27 16:05:29.707975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:loss = 5.595063, step = 77711\n",
            "I0627 16:05:30.702424 140526966839168 basic_session_run_hooks.py:262] loss = 5.595063, step = 77711\n",
            "INFO:tensorflow:global_step/sec: 3.88886\n",
            "I0627 16:05:56.416198 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 3.88886\n",
            "INFO:tensorflow:loss = 6.174002, step = 77811 (25.715 sec)\n",
            "I0627 16:05:56.417522 140526966839168 basic_session_run_hooks.py:260] loss = 6.174002, step = 77811 (25.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.54894\n",
            "I0627 16:06:18.399321 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.54894\n",
            "INFO:tensorflow:loss = 5.616246, step = 77911 (21.983 sec)\n",
            "I0627 16:06:18.400442 140526966839168 basic_session_run_hooks.py:260] loss = 5.616246, step = 77911 (21.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.52336\n",
            "I0627 16:06:40.506799 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.52336\n",
            "INFO:tensorflow:loss = 5.0986195, step = 78011 (22.108 sec)\n",
            "I0627 16:06:40.508054 140526966839168 basic_session_run_hooks.py:260] loss = 5.0986195, step = 78011 (22.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.53892\n",
            "I0627 16:07:02.538423 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.53892\n",
            "INFO:tensorflow:loss = 7.409209, step = 78111 (22.032 sec)\n",
            "I0627 16:07:02.539696 140526966839168 basic_session_run_hooks.py:260] loss = 7.409209, step = 78111 (22.032 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.55936\n",
            "I0627 16:07:24.471312 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.55936\n",
            "INFO:tensorflow:loss = 5.598552, step = 78211 (21.933 sec)\n",
            "I0627 16:07:24.472600 140526966839168 basic_session_run_hooks.py:260] loss = 5.598552, step = 78211 (21.933 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.56101\n",
            "I0627 16:07:46.396285 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.56101\n",
            "INFO:tensorflow:loss = 4.861139, step = 78311 (21.925 sec)\n",
            "I0627 16:07:46.397606 140526966839168 basic_session_run_hooks.py:260] loss = 4.861139, step = 78311 (21.925 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.53087\n",
            "I0627 16:08:08.467137 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.53087\n",
            "INFO:tensorflow:loss = 5.7760153, step = 78411 (22.071 sec)\n",
            "I0627 16:08:08.468200 140526966839168 basic_session_run_hooks.py:260] loss = 5.7760153, step = 78411 (22.071 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.56345\n",
            "I0627 16:08:30.380338 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.56345\n",
            "INFO:tensorflow:loss = 5.9640737, step = 78511 (21.913 sec)\n",
            "I0627 16:08:30.381612 140526966839168 basic_session_run_hooks.py:260] loss = 5.9640737, step = 78511 (21.913 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.59929\n",
            "I0627 16:08:52.122841 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.59929\n",
            "INFO:tensorflow:loss = 7.3526273, step = 78611 (21.742 sec)\n",
            "I0627 16:08:52.123893 140526966839168 basic_session_run_hooks.py:260] loss = 7.3526273, step = 78611 (21.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.59044\n",
            "I0627 16:09:13.907243 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.59044\n",
            "INFO:tensorflow:loss = 6.130894, step = 78711 (21.784 sec)\n",
            "I0627 16:09:13.908316 140526966839168 basic_session_run_hooks.py:260] loss = 6.130894, step = 78711 (21.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.59041\n",
            "I0627 16:09:35.691815 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.59041\n",
            "INFO:tensorflow:loss = 5.386256, step = 78811 (21.785 sec)\n",
            "I0627 16:09:35.692990 140526966839168 basic_session_run_hooks.py:260] loss = 5.386256, step = 78811 (21.785 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.56266\n",
            "I0627 16:09:57.608845 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.56266\n",
            "INFO:tensorflow:loss = 5.604025, step = 78911 (21.917 sec)\n",
            "I0627 16:09:57.609792 140526966839168 basic_session_run_hooks.py:260] loss = 5.604025, step = 78911 (21.917 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.59244\n",
            "I0627 16:10:19.383759 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.59244\n",
            "INFO:tensorflow:loss = 5.8916955, step = 79011 (21.775 sec)\n",
            "I0627 16:10:19.384827 140526966839168 basic_session_run_hooks.py:260] loss = 5.8916955, step = 79011 (21.775 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.55681\n",
            "I0627 16:10:41.328943 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.55681\n",
            "INFO:tensorflow:loss = 7.012295, step = 79111 (21.945 sec)\n",
            "I0627 16:10:41.329874 140526966839168 basic_session_run_hooks.py:260] loss = 7.012295, step = 79111 (21.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.59644\n",
            "I0627 16:11:03.084905 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.59644\n",
            "INFO:tensorflow:loss = 4.7109876, step = 79211 (21.756 sec)\n",
            "I0627 16:11:03.085933 140526966839168 basic_session_run_hooks.py:260] loss = 4.7109876, step = 79211 (21.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.60649\n",
            "I0627 16:11:24.793361 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.60649\n",
            "INFO:tensorflow:loss = 6.495804, step = 79311 (21.709 sec)\n",
            "I0627 16:11:24.794657 140526966839168 basic_session_run_hooks.py:260] loss = 6.495804, step = 79311 (21.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.56484\n",
            "I0627 16:11:46.699969 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.56484\n",
            "INFO:tensorflow:loss = 3.8916233, step = 79411 (21.907 sec)\n",
            "I0627 16:11:46.701280 140526966839168 basic_session_run_hooks.py:260] loss = 3.8916233, step = 79411 (21.907 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.58071\n",
            "I0627 16:12:08.530611 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.58071\n",
            "INFO:tensorflow:loss = 6.373494, step = 79511 (21.831 sec)\n",
            "I0627 16:12:08.531905 140526966839168 basic_session_run_hooks.py:260] loss = 6.373494, step = 79511 (21.831 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.53597\n",
            "I0627 16:12:30.576653 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.53597\n",
            "INFO:tensorflow:loss = 4.9339495, step = 79611 (22.046 sec)\n",
            "I0627 16:12:30.577752 140526966839168 basic_session_run_hooks.py:260] loss = 4.9339495, step = 79611 (22.046 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.57601\n",
            "I0627 16:12:52.429715 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.57601\n",
            "INFO:tensorflow:loss = 5.125508, step = 79711 (21.853 sec)\n",
            "I0627 16:12:52.430981 140526966839168 basic_session_run_hooks.py:260] loss = 5.125508, step = 79711 (21.853 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.52831\n",
            "I0627 16:13:14.513003 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.52831\n",
            "INFO:tensorflow:loss = 5.8836737, step = 79811 (22.083 sec)\n",
            "I0627 16:13:14.514090 140526966839168 basic_session_run_hooks.py:260] loss = 5.8836737, step = 79811 (22.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.52617\n",
            "I0627 16:13:36.606728 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.52617\n",
            "INFO:tensorflow:loss = 5.6560235, step = 79911 (22.094 sec)\n",
            "I0627 16:13:36.607828 140526966839168 basic_session_run_hooks.py:260] loss = 5.6560235, step = 79911 (22.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.50768\n",
            "I0627 16:13:58.791086 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.50768\n",
            "INFO:tensorflow:loss = 6.1637, step = 80011 (22.185 sec)\n",
            "I0627 16:13:58.792422 140526966839168 basic_session_run_hooks.py:260] loss = 6.1637, step = 80011 (22.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.52786\n",
            "I0627 16:14:20.876587 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.52786\n",
            "INFO:tensorflow:loss = 6.6341753, step = 80111 (22.085 sec)\n",
            "I0627 16:14:20.877727 140526966839168 basic_session_run_hooks.py:260] loss = 6.6341753, step = 80111 (22.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.50998\n",
            "I0627 16:14:43.049625 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.50998\n",
            "INFO:tensorflow:loss = 5.9899893, step = 80211 (22.173 sec)\n",
            "I0627 16:14:43.050721 140526966839168 basic_session_run_hooks.py:260] loss = 5.9899893, step = 80211 (22.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.51461\n",
            "I0627 16:15:05.199937 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.51461\n",
            "INFO:tensorflow:loss = 4.8979807, step = 80311 (22.150 sec)\n",
            "I0627 16:15:05.201103 140526966839168 basic_session_run_hooks.py:260] loss = 4.8979807, step = 80311 (22.150 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 80390 into training/model.ckpt.\n",
            "I0627 16:15:22.574532 140526966839168 basic_session_run_hooks.py:606] Saving checkpoints for 80390 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0627 16:15:22.674785 140526966839168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0627 16:15:24.997162 140526966839168 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:15:27.073045 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:15:27.104963 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:15:27.140283 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:15:27.168833 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:15:27.196664 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:15:27.226067 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 16:15:29.005308 140526966839168 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0627 16:15:29.207616 140526966839168 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0627 16:15:29.709398 140526966839168 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-27T16:15:29Z\n",
            "I0627 16:15:29.726132 140526966839168 evaluation.py:255] Starting evaluation at 2020-06-27T16:15:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0627 16:15:30.121889 140526966839168 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-27 16:15:30.123127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:15:30.123736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-27 16:15:30.123881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-27 16:15:30.123912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-27 16:15:30.123933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-27 16:15:30.123956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-27 16:15:30.123983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-27 16:15:30.124003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-27 16:15:30.124023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-27 16:15:30.124148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:15:30.124659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:15:30.125073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-27 16:15:30.125155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-27 16:15:30.125169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-27 16:15:30.125178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-27 16:15:30.125309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:15:30.125838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:15:30.126317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-80390\n",
            "I0627 16:15:30.127448 140526966839168 saver.py:1284] Restoring parameters from training/model.ckpt-80390\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0627 16:15:31.100253 140526966839168 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0627 16:15:31.266301 140526966839168 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 4658 images.\n",
            "I0627 16:19:43.311646 140523125413632 coco_evaluation.py:237] Performing evaluation on 4658 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0627 16:19:43.328828 140523125413632 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.35s)\n",
            "I0627 16:19:43.675717 140523125413632 coco_tools.py:138] DONE (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=29.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=5.63s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-27-16:20:19\n",
            "I0627 16:20:19.456097 140526966839168 evaluation.py:275] Finished evaluation at 2020-06-27-16:20:19\n",
            "INFO:tensorflow:Saving dict for global step 80390: DetectionBoxes_Precision/mAP = 0.22015934, DetectionBoxes_Precision/mAP (large) = 0.24355716, DetectionBoxes_Precision/mAP (medium) = 0.011204746, DetectionBoxes_Precision/mAP (small) = 5.8646683e-06, DetectionBoxes_Precision/mAP@.50IOU = 0.4110346, DetectionBoxes_Precision/mAP@.75IOU = 0.20666647, DetectionBoxes_Recall/AR@1 = 0.24320845, DetectionBoxes_Recall/AR@10 = 0.3577633, DetectionBoxes_Recall/AR@100 = 0.4090741, DetectionBoxes_Recall/AR@100 (large) = 0.4612497, DetectionBoxes_Recall/AR@100 (medium) = 0.066905305, DetectionBoxes_Recall/AR@100 (small) = 0.00062354445, Loss/classification_loss = 5.5130773, Loss/localization_loss = 1.3881515, Loss/regularization_loss = 0.33374837, Loss/total_loss = 7.2349896, global_step = 80390, learning_rate = 0.004, loss = 7.2349896\n",
            "I0627 16:20:19.456448 140526966839168 estimator.py:2049] Saving dict for global step 80390: DetectionBoxes_Precision/mAP = 0.22015934, DetectionBoxes_Precision/mAP (large) = 0.24355716, DetectionBoxes_Precision/mAP (medium) = 0.011204746, DetectionBoxes_Precision/mAP (small) = 5.8646683e-06, DetectionBoxes_Precision/mAP@.50IOU = 0.4110346, DetectionBoxes_Precision/mAP@.75IOU = 0.20666647, DetectionBoxes_Recall/AR@1 = 0.24320845, DetectionBoxes_Recall/AR@10 = 0.3577633, DetectionBoxes_Recall/AR@100 = 0.4090741, DetectionBoxes_Recall/AR@100 (large) = 0.4612497, DetectionBoxes_Recall/AR@100 (medium) = 0.066905305, DetectionBoxes_Recall/AR@100 (small) = 0.00062354445, Loss/classification_loss = 5.5130773, Loss/localization_loss = 1.3881515, Loss/regularization_loss = 0.33374837, Loss/total_loss = 7.2349896, global_step = 80390, learning_rate = 0.004, loss = 7.2349896\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 80390: training/model.ckpt-80390\n",
            "I0627 16:20:20.620025 140526966839168 estimator.py:2109] Saving 'checkpoint_path' summary for global step 80390: training/model.ckpt-80390\n",
            "INFO:tensorflow:global_step/sec: 0.312112\n",
            "I0627 16:20:25.597898 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 0.312112\n",
            "INFO:tensorflow:loss = 6.4373636, step = 80411 (320.398 sec)\n",
            "I0627 16:20:25.599103 140526966839168 basic_session_run_hooks.py:260] loss = 6.4373636, step = 80411 (320.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.46097\n",
            "I0627 16:20:48.014504 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.46097\n",
            "INFO:tensorflow:loss = 5.9890685, step = 80511 (22.416 sec)\n",
            "I0627 16:20:48.015589 140526966839168 basic_session_run_hooks.py:260] loss = 5.9890685, step = 80511 (22.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.46636\n",
            "I0627 16:21:10.404107 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.46636\n",
            "INFO:tensorflow:loss = 4.9920444, step = 80611 (22.389 sec)\n",
            "I0627 16:21:10.405080 140526966839168 basic_session_run_hooks.py:260] loss = 4.9920444, step = 80611 (22.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.44371\n",
            "I0627 16:21:32.907869 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.44371\n",
            "INFO:tensorflow:loss = 4.8941083, step = 80711 (22.504 sec)\n",
            "I0627 16:21:32.909140 140526966839168 basic_session_run_hooks.py:260] loss = 4.8941083, step = 80711 (22.504 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.46755\n",
            "I0627 16:21:55.291491 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.46755\n",
            "INFO:tensorflow:loss = 5.7367973, step = 80811 (22.384 sec)\n",
            "I0627 16:21:55.292700 140526966839168 basic_session_run_hooks.py:260] loss = 5.7367973, step = 80811 (22.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.46915\n",
            "I0627 16:22:17.667147 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.46915\n",
            "INFO:tensorflow:loss = 5.9265275, step = 80911 (22.375 sec)\n",
            "I0627 16:22:17.668155 140526966839168 basic_session_run_hooks.py:260] loss = 5.9265275, step = 80911 (22.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.45127\n",
            "I0627 16:22:40.132639 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.45127\n",
            "INFO:tensorflow:loss = 5.3176613, step = 81011 (22.466 sec)\n",
            "I0627 16:22:40.133911 140526966839168 basic_session_run_hooks.py:260] loss = 5.3176613, step = 81011 (22.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.47614\n",
            "I0627 16:23:02.473276 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.47614\n",
            "INFO:tensorflow:loss = 6.5996466, step = 81111 (22.341 sec)\n",
            "I0627 16:23:02.474438 140526966839168 basic_session_run_hooks.py:260] loss = 6.5996466, step = 81111 (22.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.4692\n",
            "I0627 16:23:24.848706 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.4692\n",
            "INFO:tensorflow:loss = 5.4642453, step = 81211 (22.376 sec)\n",
            "I0627 16:23:24.850174 140526966839168 basic_session_run_hooks.py:260] loss = 5.4642453, step = 81211 (22.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.48946\n",
            "I0627 16:23:47.123035 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.48946\n",
            "INFO:tensorflow:loss = 5.436487, step = 81311 (22.274 sec)\n",
            "I0627 16:23:47.124183 140526966839168 basic_session_run_hooks.py:260] loss = 5.436487, step = 81311 (22.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.48604\n",
            "I0627 16:24:09.414433 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.48604\n",
            "INFO:tensorflow:loss = 6.279623, step = 81411 (22.291 sec)\n",
            "I0627 16:24:09.415515 140526966839168 basic_session_run_hooks.py:260] loss = 6.279623, step = 81411 (22.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.52348\n",
            "I0627 16:24:31.521318 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.52348\n",
            "INFO:tensorflow:loss = 4.9661922, step = 81511 (22.107 sec)\n",
            "I0627 16:24:31.522425 140526966839168 basic_session_run_hooks.py:260] loss = 4.9661922, step = 81511 (22.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.50337\n",
            "I0627 16:24:53.726907 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.50337\n",
            "INFO:tensorflow:loss = 5.6530976, step = 81611 (22.206 sec)\n",
            "I0627 16:24:53.728015 140526966839168 basic_session_run_hooks.py:260] loss = 5.6530976, step = 81611 (22.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.49674\n",
            "I0627 16:25:15.965234 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.49674\n",
            "INFO:tensorflow:loss = 5.0415545, step = 81711 (22.238 sec)\n",
            "I0627 16:25:15.966155 140526966839168 basic_session_run_hooks.py:260] loss = 5.0415545, step = 81711 (22.238 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 81742 into training/model.ckpt.\n",
            "I0627 16:25:22.675107 140526966839168 basic_session_run_hooks.py:606] Saving checkpoints for 81742 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0627 16:25:24.822088 140526966839168 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:25:26.842313 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:25:26.871551 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:25:26.899526 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:25:26.928174 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:25:26.957487 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:25:26.986666 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0627 16:25:29.434161 140526966839168 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-27T16:25:29Z\n",
            "I0627 16:25:29.449741 140526966839168 evaluation.py:255] Starting evaluation at 2020-06-27T16:25:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0627 16:25:29.878295 140526966839168 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-27 16:25:29.879131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:25:29.879613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-27 16:25:29.879729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-27 16:25:29.879760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-27 16:25:29.879806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-27 16:25:29.879832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-27 16:25:29.879853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-27 16:25:29.879873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-27 16:25:29.879893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-27 16:25:29.880008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:25:29.880500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:25:29.880917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-27 16:25:29.881248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-27 16:25:29.881268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-27 16:25:29.881277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-27 16:25:29.881477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:25:29.881990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:25:29.882404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-81742\n",
            "I0627 16:25:29.883362 140526966839168 saver.py:1284] Restoring parameters from training/model.ckpt-81742\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0627 16:25:30.874895 140526966839168 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0627 16:25:31.018619 140526966839168 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 4658 images.\n",
            "I0627 16:29:45.285945 140523117020928 coco_evaluation.py:237] Performing evaluation on 4658 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0627 16:29:45.301092 140523117020928 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.35s)\n",
            "I0627 16:29:45.655755 140523117020928 coco_tools.py:138] DONE (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=25.59s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=5.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.490\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-27-16:30:17\n",
            "I0627 16:30:17.234368 140526966839168 evaluation.py:275] Finished evaluation at 2020-06-27-16:30:17\n",
            "INFO:tensorflow:Saving dict for global step 81742: DetectionBoxes_Precision/mAP = 0.24966373, DetectionBoxes_Precision/mAP (large) = 0.27624062, DetectionBoxes_Precision/mAP (medium) = 0.017752295, DetectionBoxes_Precision/mAP (small) = 4.5357892e-06, DetectionBoxes_Precision/mAP@.50IOU = 0.48973694, DetectionBoxes_Precision/mAP@.75IOU = 0.2294066, DetectionBoxes_Recall/AR@1 = 0.2678382, DetectionBoxes_Recall/AR@10 = 0.39722875, DetectionBoxes_Recall/AR@100 = 0.4479973, DetectionBoxes_Recall/AR@100 (large) = 0.50497794, DetectionBoxes_Recall/AR@100 (medium) = 0.097416475, DetectionBoxes_Recall/AR@100 (small) = 0.00054090604, Loss/classification_loss = 5.3041334, Loss/localization_loss = 1.3509885, Loss/regularization_loss = 0.33516756, Loss/total_loss = 6.990282, global_step = 81742, learning_rate = 0.004, loss = 6.990282\n",
            "I0627 16:30:17.234665 140526966839168 estimator.py:2049] Saving dict for global step 81742: DetectionBoxes_Precision/mAP = 0.24966373, DetectionBoxes_Precision/mAP (large) = 0.27624062, DetectionBoxes_Precision/mAP (medium) = 0.017752295, DetectionBoxes_Precision/mAP (small) = 4.5357892e-06, DetectionBoxes_Precision/mAP@.50IOU = 0.48973694, DetectionBoxes_Precision/mAP@.75IOU = 0.2294066, DetectionBoxes_Recall/AR@1 = 0.2678382, DetectionBoxes_Recall/AR@10 = 0.39722875, DetectionBoxes_Recall/AR@100 = 0.4479973, DetectionBoxes_Recall/AR@100 (large) = 0.50497794, DetectionBoxes_Recall/AR@100 (medium) = 0.097416475, DetectionBoxes_Recall/AR@100 (small) = 0.00054090604, Loss/classification_loss = 5.3041334, Loss/localization_loss = 1.3509885, Loss/regularization_loss = 0.33516756, Loss/total_loss = 6.990282, global_step = 81742, learning_rate = 0.004, loss = 6.990282\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 81742: training/model.ckpt-81742\n",
            "I0627 16:30:17.238212 140526966839168 estimator.py:2109] Saving 'checkpoint_path' summary for global step 81742: training/model.ckpt-81742\n",
            "INFO:tensorflow:global_step/sec: 0.315381\n",
            "I0627 16:30:33.041640 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 0.315381\n",
            "INFO:tensorflow:loss = 5.71411, step = 81811 (317.077 sec)\n",
            "I0627 16:30:33.042759 140526966839168 basic_session_run_hooks.py:260] loss = 5.71411, step = 81811 (317.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.45153\n",
            "I0627 16:30:55.505812 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.45153\n",
            "INFO:tensorflow:loss = 6.405553, step = 81911 (22.464 sec)\n",
            "I0627 16:30:55.507016 140526966839168 basic_session_run_hooks.py:260] loss = 6.405553, step = 81911 (22.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.45356\n",
            "I0627 16:31:17.959805 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.45356\n",
            "INFO:tensorflow:loss = 6.3806186, step = 82011 (22.454 sec)\n",
            "I0627 16:31:17.961076 140526966839168 basic_session_run_hooks.py:260] loss = 6.3806186, step = 82011 (22.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.4348\n",
            "I0627 16:31:40.508732 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.4348\n",
            "INFO:tensorflow:loss = 6.0882707, step = 82111 (22.549 sec)\n",
            "I0627 16:31:40.509818 140526966839168 basic_session_run_hooks.py:260] loss = 6.0882707, step = 82111 (22.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.43263\n",
            "I0627 16:32:03.068708 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.43263\n",
            "INFO:tensorflow:loss = 5.1743293, step = 82211 (22.560 sec)\n",
            "I0627 16:32:03.069840 140526966839168 basic_session_run_hooks.py:260] loss = 5.1743293, step = 82211 (22.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.41786\n",
            "I0627 16:32:25.704092 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.41786\n",
            "INFO:tensorflow:loss = 5.1623893, step = 82311 (22.635 sec)\n",
            "I0627 16:32:25.705036 140526966839168 basic_session_run_hooks.py:260] loss = 5.1623893, step = 82311 (22.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.43676\n",
            "I0627 16:32:48.243060 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.43676\n",
            "INFO:tensorflow:loss = 6.4245253, step = 82411 (22.539 sec)\n",
            "I0627 16:32:48.244421 140526966839168 basic_session_run_hooks.py:260] loss = 6.4245253, step = 82411 (22.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.44225\n",
            "I0627 16:33:10.754166 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.44225\n",
            "INFO:tensorflow:loss = 6.2723413, step = 82511 (22.511 sec)\n",
            "I0627 16:33:10.755382 140526966839168 basic_session_run_hooks.py:260] loss = 6.2723413, step = 82511 (22.511 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.41617\n",
            "I0627 16:33:33.398232 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.41617\n",
            "INFO:tensorflow:loss = 5.0391254, step = 82611 (22.644 sec)\n",
            "I0627 16:33:33.399354 140526966839168 basic_session_run_hooks.py:260] loss = 5.0391254, step = 82611 (22.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.43245\n",
            "I0627 16:33:55.959088 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.43245\n",
            "INFO:tensorflow:loss = 5.465015, step = 82711 (22.561 sec)\n",
            "I0627 16:33:55.960152 140526966839168 basic_session_run_hooks.py:260] loss = 5.465015, step = 82711 (22.561 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.44076\n",
            "I0627 16:34:18.477828 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.44076\n",
            "INFO:tensorflow:loss = 5.521097, step = 82811 (22.519 sec)\n",
            "I0627 16:34:18.478869 140526966839168 basic_session_run_hooks.py:260] loss = 5.521097, step = 82811 (22.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.40728\n",
            "I0627 16:34:41.167541 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.40728\n",
            "INFO:tensorflow:loss = 5.539999, step = 82911 (22.690 sec)\n",
            "I0627 16:34:41.168634 140526966839168 basic_session_run_hooks.py:260] loss = 5.539999, step = 82911 (22.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.45599\n",
            "I0627 16:35:03.609236 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.45599\n",
            "INFO:tensorflow:loss = 5.811556, step = 83011 (22.442 sec)\n",
            "I0627 16:35:03.610244 140526966839168 basic_session_run_hooks.py:260] loss = 5.811556, step = 83011 (22.442 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 83097 into training/model.ckpt.\n",
            "I0627 16:35:22.749131 140526966839168 basic_session_run_hooks.py:606] Saving checkpoints for 83097 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0627 16:35:25.033034 140526966839168 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:35:27.142415 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:35:27.172887 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:35:27.206670 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:35:27.241091 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:35:27.270694 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:35:27.300149 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0627 16:35:29.864486 140526966839168 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-27T16:35:29Z\n",
            "I0627 16:35:29.882304 140526966839168 evaluation.py:255] Starting evaluation at 2020-06-27T16:35:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0627 16:35:30.347581 140526966839168 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-27 16:35:30.348352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:35:30.348957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-27 16:35:30.349081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-27 16:35:30.349122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-27 16:35:30.349146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-27 16:35:30.349176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-27 16:35:30.349199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-27 16:35:30.349221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-27 16:35:30.349244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-27 16:35:30.349374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:35:30.350000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:35:30.350488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-27 16:35:30.350541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-27 16:35:30.350573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-27 16:35:30.350584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-27 16:35:30.350725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:35:30.351348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:35:30.351845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-83097\n",
            "I0627 16:35:30.353008 140526966839168 saver.py:1284] Restoring parameters from training/model.ckpt-83097\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0627 16:35:31.381650 140526966839168 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0627 16:35:31.539314 140526966839168 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 4658 images.\n",
            "I0627 16:39:52.289021 140523117020928 coco_evaluation.py:237] Performing evaluation on 4658 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0627 16:39:52.304657 140523117020928 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.38s)\n",
            "I0627 16:39:52.687031 140523117020928 coco_tools.py:138] DONE (t=0.38s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=24.79s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=5.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.486\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-27-16:40:23\n",
            "I0627 16:40:23.749211 140526966839168 evaluation.py:275] Finished evaluation at 2020-06-27-16:40:23\n",
            "INFO:tensorflow:Saving dict for global step 83097: DetectionBoxes_Precision/mAP = 0.26549152, DetectionBoxes_Precision/mAP (large) = 0.29109025, DetectionBoxes_Precision/mAP (medium) = 0.027488232, DetectionBoxes_Precision/mAP (small) = 1.4234839e-05, DetectionBoxes_Precision/mAP@.50IOU = 0.48594686, DetectionBoxes_Precision/mAP@.75IOU = 0.2460358, DetectionBoxes_Recall/AR@1 = 0.28138217, DetectionBoxes_Recall/AR@10 = 0.41160902, DetectionBoxes_Recall/AR@100 = 0.45919105, DetectionBoxes_Recall/AR@100 (large) = 0.516545, DetectionBoxes_Recall/AR@100 (medium) = 0.10156989, DetectionBoxes_Recall/AR@100 (small) = 0.001262114, Loss/classification_loss = 5.1699457, Loss/localization_loss = 1.3001183, Loss/regularization_loss = 0.3365155, Loss/total_loss = 6.8065524, global_step = 83097, learning_rate = 0.004, loss = 6.8065524\n",
            "I0627 16:40:23.749497 140526966839168 estimator.py:2049] Saving dict for global step 83097: DetectionBoxes_Precision/mAP = 0.26549152, DetectionBoxes_Precision/mAP (large) = 0.29109025, DetectionBoxes_Precision/mAP (medium) = 0.027488232, DetectionBoxes_Precision/mAP (small) = 1.4234839e-05, DetectionBoxes_Precision/mAP@.50IOU = 0.48594686, DetectionBoxes_Precision/mAP@.75IOU = 0.2460358, DetectionBoxes_Recall/AR@1 = 0.28138217, DetectionBoxes_Recall/AR@10 = 0.41160902, DetectionBoxes_Recall/AR@100 = 0.45919105, DetectionBoxes_Recall/AR@100 (large) = 0.516545, DetectionBoxes_Recall/AR@100 (medium) = 0.10156989, DetectionBoxes_Recall/AR@100 (small) = 0.001262114, Loss/classification_loss = 5.1699457, Loss/localization_loss = 1.3001183, Loss/regularization_loss = 0.3365155, Loss/total_loss = 6.8065524, global_step = 83097, learning_rate = 0.004, loss = 6.8065524\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 83097: training/model.ckpt-83097\n",
            "I0627 16:40:23.752761 140526966839168 estimator.py:2109] Saving 'checkpoint_path' summary for global step 83097: training/model.ckpt-83097\n",
            "INFO:tensorflow:global_step/sec: 0.309028\n",
            "I0627 16:40:27.204097 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 0.309028\n",
            "INFO:tensorflow:loss = 4.9268765, step = 83111 (323.595 sec)\n",
            "I0627 16:40:27.205071 140526966839168 basic_session_run_hooks.py:260] loss = 4.9268765, step = 83111 (323.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.37567\n",
            "I0627 16:40:50.057696 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.37567\n",
            "INFO:tensorflow:loss = 5.3689513, step = 83211 (22.854 sec)\n",
            "I0627 16:40:50.059097 140526966839168 basic_session_run_hooks.py:260] loss = 5.3689513, step = 83211 (22.854 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.42148\n",
            "I0627 16:41:12.674536 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.42148\n",
            "INFO:tensorflow:loss = 6.6627674, step = 83311 (22.617 sec)\n",
            "I0627 16:41:12.675607 140526966839168 basic_session_run_hooks.py:260] loss = 6.6627674, step = 83311 (22.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.41263\n",
            "I0627 16:41:35.336802 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.41263\n",
            "INFO:tensorflow:loss = 5.5701475, step = 83411 (22.662 sec)\n",
            "I0627 16:41:35.337993 140526966839168 basic_session_run_hooks.py:260] loss = 5.5701475, step = 83411 (22.662 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.39559\n",
            "I0627 16:41:58.086925 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.39559\n",
            "INFO:tensorflow:loss = 6.2161255, step = 83511 (22.750 sec)\n",
            "I0627 16:41:58.088068 140526966839168 basic_session_run_hooks.py:260] loss = 6.2161255, step = 83511 (22.750 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.37801\n",
            "I0627 16:42:20.928285 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.37801\n",
            "INFO:tensorflow:loss = 5.2941155, step = 83611 (22.841 sec)\n",
            "I0627 16:42:20.929342 140526966839168 basic_session_run_hooks.py:260] loss = 5.2941155, step = 83611 (22.841 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.36675\n",
            "I0627 16:42:43.828588 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.36675\n",
            "INFO:tensorflow:loss = 5.94382, step = 83711 (22.901 sec)\n",
            "I0627 16:42:43.829890 140526966839168 basic_session_run_hooks.py:260] loss = 5.94382, step = 83711 (22.901 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.3996\n",
            "I0627 16:43:06.557940 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.3996\n",
            "INFO:tensorflow:loss = 5.8426085, step = 83811 (22.729 sec)\n",
            "I0627 16:43:06.559280 140526966839168 basic_session_run_hooks.py:260] loss = 5.8426085, step = 83811 (22.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.39522\n",
            "I0627 16:43:29.309935 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.39522\n",
            "INFO:tensorflow:loss = 5.124761, step = 83911 (22.752 sec)\n",
            "I0627 16:43:29.311209 140526966839168 basic_session_run_hooks.py:260] loss = 5.124761, step = 83911 (22.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.40347\n",
            "I0627 16:43:52.019276 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.40347\n",
            "INFO:tensorflow:loss = 4.2455115, step = 84011 (22.709 sec)\n",
            "I0627 16:43:52.020450 140526966839168 basic_session_run_hooks.py:260] loss = 4.2455115, step = 84011 (22.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.42935\n",
            "I0627 16:44:14.595993 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.42935\n",
            "INFO:tensorflow:loss = 5.596177, step = 84111 (22.577 sec)\n",
            "I0627 16:44:14.597307 140526966839168 basic_session_run_hooks.py:260] loss = 5.596177, step = 84111 (22.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.40416\n",
            "I0627 16:44:37.301751 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.40416\n",
            "INFO:tensorflow:loss = 4.662621, step = 84211 (22.706 sec)\n",
            "I0627 16:44:37.303062 140526966839168 basic_session_run_hooks.py:260] loss = 4.662621, step = 84211 (22.706 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.40813\n",
            "I0627 16:44:59.987053 140526966839168 basic_session_run_hooks.py:692] global_step/sec: 4.40813\n",
            "INFO:tensorflow:loss = 5.775587, step = 84311 (22.685 sec)\n",
            "I0627 16:44:59.988495 140526966839168 basic_session_run_hooks.py:260] loss = 5.775587, step = 84311 (22.685 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 84412 into training/model.ckpt.\n",
            "I0627 16:45:22.770392 140526966839168 basic_session_run_hooks.py:606] Saving checkpoints for 84412 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0627 16:45:25.081018 140526966839168 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:45:27.271596 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:45:27.303357 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:45:27.343516 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:45:27.374047 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:45:27.403792 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0627 16:45:27.432516 140526966839168 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0627 16:45:29.954045 140526966839168 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-27T16:45:29Z\n",
            "I0627 16:45:29.970387 140526966839168 evaluation.py:255] Starting evaluation at 2020-06-27T16:45:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0627 16:45:30.384507 140526966839168 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-27 16:45:30.385341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:45:30.385948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-27 16:45:30.386050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-27 16:45:30.386085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-27 16:45:30.386121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-27 16:45:30.386147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-27 16:45:30.386173: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-27 16:45:30.386194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-27 16:45:30.386215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-27 16:45:30.386342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:45:30.386912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:45:30.387364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-27 16:45:30.387411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-27 16:45:30.387438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-27 16:45:30.387448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-27 16:45:30.387574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:45:30.388101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-27 16:45:30.388563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-84412\n",
            "I0627 16:45:30.389659 140526966839168 saver.py:1284] Restoring parameters from training/model.ckpt-84412\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0627 16:45:31.439291 140526966839168 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0627 16:45:31.605144 140526966839168 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 4658 images.\n",
            "I0627 16:49:56.505361 140523125413632 coco_evaluation.py:237] Performing evaluation on 4658 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0627 16:49:56.520397 140523125413632 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.39s)\n",
            "I0627 16:49:56.906420 140523125413632 coco_tools.py:138] DONE (t=0.39s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clpWmCaEktit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6obduofHkyaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Legacy way of training(also works).\n",
        "#!python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEthu2FfEFKT",
        "colab_type": "text"
      },
      "source": [
        "#To know the remaining time for google colab session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piWpekVkEDtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14816cbb-7482-4a6c-a8c2-be6cb18c1689"
      },
      "source": [
        "import time, psutil\n",
        "Start = time.time()- psutil.boot_time()\n",
        "Left= 12*3600 - Start\n",
        "print('Time remaining for this session is: ', Left/3600)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time remaining for this session is:  2.729322369231118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGRijFVfELwN",
        "colab_type": "text"
      },
      "source": [
        "##Saving the model for next training in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C54grHKtA9rQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6fd96e6d-222f-4780-a9e1-a4bea15d8304"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo8ira3ZBA8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/file.zip /content/models/research/training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoJ8uEUM3rXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "044efeda-f649-4ede-e513-32c26d58430a"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_968434ca-b904-49da-9441-6295ebe2553d\", \"file.zip\", 456555874)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa_7-tHC4Nye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/pretrained.zip /content/models/research/pretrained_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmZzPTdv4T33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/pretrained.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzYNllBICNxg",
        "colab_type": "text"
      },
      "source": [
        "#For the purpose of continuing training after runtime restart (after <=12 hrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnmRu94PCFHT",
        "colab_type": "text"
      },
      "source": [
        "##Download each of `training/` files to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0nhB30TN3d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "3ade47d6-370a-4733-fbbc-ae9960a0d4ca"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "#events\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593241039.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/events.out.tfevents.1593241039.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593241213.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/events.out.tfevents.1593241213.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593265610.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/events.out.tfevents.1593265610.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593269394.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/events.out.tfevents.1593269394.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593273905.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/events.out.tfevents.1593273905.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "#graph\n",
        "uploaded = drive.CreateFile({'title': 'graph.pbtxt'})\n",
        "uploaded.SetContentFile('/content/models/research/training/graph.pbtxt')\n",
        "uploaded.Upload()\n",
        "\n",
        "#1\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-81742.data-00000-of-00001'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-81742.data-00000-of-00001')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-81742.index'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-81742.index')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-81742.meta'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-81742.meta')\n",
        "uploaded.Upload()\n",
        "\n",
        "#2\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-80390.data-00000-of-00001'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-80390.data-00000-of-00001')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-80390.index'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-80390.index')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-80390.meta'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-80390.meta')\n",
        "uploaded.Upload()\n",
        "\n",
        "\n",
        "#2\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-74859.data-00000-of-00001'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-74859.data-00000-of-00001')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-74859.index'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-74859.index')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-74859.meta'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-74859.meta')\n",
        "uploaded.Upload()\n",
        "\n",
        "#2\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-76273.data-00000-of-00001'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-76273.data-00000-of-00001')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-76273.index'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-76273.index')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-76273.meta'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-76273.meta')\n",
        "uploaded.Upload()\n",
        "\n",
        "#2\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-77711.data-00000-of-00001'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-77711.data-00000-of-00001')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-77711.index'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-77711.index')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt-77711.meta'})\n",
        "uploaded.SetContentFile('/content/models/research/training/model.ckpt-77711.meta')\n",
        "uploaded.Upload()\n",
        "\n",
        "\n",
        "#checkpoint\n",
        "uploaded = drive.CreateFile({'title': 'checkpoint'})\n",
        "uploaded.SetContentFile('/content/models/research/training/checkpoint')\n",
        "uploaded.Upload()\n",
        "\n",
        "#eval_0\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593242115.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/eval_0/events.out.tfevents.1593242115.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593266504.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/eval_0/events.out.tfevents.1593266504.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593270309.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/eval_0/events.out.tfevents.1593270309.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'events.out.tfevents.1593274820.dba4504e9c5b'})\n",
        "uploaded.SetContentFile('/content/models/research/training/eval_0/events.out.tfevents.1593274820.dba4504e9c5b')\n",
        "uploaded.Upload()\n",
        "\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63b2958db1b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'events.out.tfevents.1593241039.dba4504e9c5b'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/models/research/training/events.out.tfevents.1593241039.dba4504e9c5b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mSetContentFile\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/models/research/training/events.out.tfevents.1593241039.dba4504e9c5b'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHknpPtgCayy",
        "colab_type": "text"
      },
      "source": [
        "##Download each of `pretrained_model/` to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUxGbW6PAV5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7baa319a-35f4-4128-b31b-0ffdb9592103"
      },
      "source": [
        "uploaded = drive.CreateFile({'title': 'saved_model.pb'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/saved_model/saved_model.pb')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'checkpoint'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/checkpoint')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt.data-00000-of-00001'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/model.ckpt.data-00000-of-00001')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt.index'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/model.ckpt.index')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.ckpt.meta'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/model.ckpt.meta')\n",
        "uploaded.Upload()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'frozen_inference_graph.pb'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/frozen_inference_graph.pb')\n",
        "uploaded.Upload()\n",
        "\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'pipeline.config'})\n",
        "uploaded.SetContentFile('/content/models/research/pretrained_model/pipeline.config')\n",
        "uploaded.Upload()\n",
        "\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1oELSczIDam-_pF07kZSWK0V5A3Zxko5q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HVGPdNpk04U",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34sPKhNxk34G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuuF0W0Ck8xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcUTu4tzk_V7",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cORg_2alBvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF-gPnlIlFtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg_8WhaBlIlr",
        "colab_type": "text"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grqlf0arlKQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K-Xw6SrlOEb",
        "colab_type": "text"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TQzkoPplP51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha2jylZNlU2l",
        "colab_type": "text"
      },
      "source": [
        "### Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX0I95iwlVht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAD1OJ4-lZF0",
        "colab_type": "text"
      },
      "source": [
        "### Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FgmBQuzlZmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cumCoID5leFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwpXzAXglf6T",
        "colab_type": "text"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `object_detection_demo/test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIhHMDLAlgas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct2Vt9zpljY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}